{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importamos librerias y leemos los archivos de datos. \n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import f1_score\n",
    "import lightgbm as lgb\n",
    "\n",
    "train_values = pd.read_csv('train_values.csv', index_col='building_id')\n",
    "train_labels = pd.read_csv('train_labels.csv', index_col='building_id')\n",
    "\n",
    "test_values = pd.read_csv('test_values.csv', index_col='building_id')\n",
    "submission_format = pd.read_csv('submission_format.csv', index_col='building_id')\n",
    "\n",
    "train_values = pd.get_dummies(train_values)\n",
    "test_values = pd.get_dummies(test_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024673 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 817\n",
      "[LightGBM] [Info] Number of data points in the train set: 260601, number of used features: 68\n",
      "[LightGBM] [Info] Start training from score 2.238272\n",
      "[1]\tvalid_0's l2: 0.35129\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's l2: 0.332626\n",
      "[3]\tvalid_0's l2: 0.317458\n",
      "[4]\tvalid_0's l2: 0.305029\n",
      "[5]\tvalid_0's l2: 0.294809\n",
      "[6]\tvalid_0's l2: 0.28644\n",
      "[7]\tvalid_0's l2: 0.279538\n",
      "[8]\tvalid_0's l2: 0.273715\n",
      "[9]\tvalid_0's l2: 0.268834\n",
      "[10]\tvalid_0's l2: 0.26479\n",
      "[11]\tvalid_0's l2: 0.261324\n",
      "[12]\tvalid_0's l2: 0.258593\n",
      "[13]\tvalid_0's l2: 0.256082\n",
      "[14]\tvalid_0's l2: 0.254043\n",
      "[15]\tvalid_0's l2: 0.251878\n",
      "[16]\tvalid_0's l2: 0.250142\n",
      "[17]\tvalid_0's l2: 0.248852\n",
      "[18]\tvalid_0's l2: 0.247551\n",
      "[19]\tvalid_0's l2: 0.246569\n",
      "[20]\tvalid_0's l2: 0.245619\n",
      "[21]\tvalid_0's l2: 0.244575\n",
      "[22]\tvalid_0's l2: 0.243884\n",
      "[23]\tvalid_0's l2: 0.243081\n",
      "[24]\tvalid_0's l2: 0.242289\n",
      "[25]\tvalid_0's l2: 0.241756\n",
      "[26]\tvalid_0's l2: 0.24125\n",
      "[27]\tvalid_0's l2: 0.240683\n",
      "[28]\tvalid_0's l2: 0.240237\n",
      "[29]\tvalid_0's l2: 0.239784\n",
      "[30]\tvalid_0's l2: 0.239315\n",
      "[31]\tvalid_0's l2: 0.23877\n",
      "[32]\tvalid_0's l2: 0.238442\n",
      "[33]\tvalid_0's l2: 0.238112\n",
      "[34]\tvalid_0's l2: 0.237734\n",
      "[35]\tvalid_0's l2: 0.237263\n",
      "[36]\tvalid_0's l2: 0.236635\n",
      "[37]\tvalid_0's l2: 0.23636\n",
      "[38]\tvalid_0's l2: 0.235961\n",
      "[39]\tvalid_0's l2: 0.235663\n",
      "[40]\tvalid_0's l2: 0.235297\n",
      "[41]\tvalid_0's l2: 0.235077\n",
      "[42]\tvalid_0's l2: 0.234779\n",
      "[43]\tvalid_0's l2: 0.234436\n",
      "[44]\tvalid_0's l2: 0.234072\n",
      "[45]\tvalid_0's l2: 0.233737\n",
      "[46]\tvalid_0's l2: 0.233546\n",
      "[47]\tvalid_0's l2: 0.233286\n",
      "[48]\tvalid_0's l2: 0.233067\n",
      "[49]\tvalid_0's l2: 0.232645\n",
      "[50]\tvalid_0's l2: 0.232346\n",
      "[51]\tvalid_0's l2: 0.231963\n",
      "[52]\tvalid_0's l2: 0.231564\n",
      "[53]\tvalid_0's l2: 0.23125\n",
      "[54]\tvalid_0's l2: 0.230909\n",
      "[55]\tvalid_0's l2: 0.230706\n",
      "[56]\tvalid_0's l2: 0.230528\n",
      "[57]\tvalid_0's l2: 0.230316\n",
      "[58]\tvalid_0's l2: 0.230085\n",
      "[59]\tvalid_0's l2: 0.22991\n",
      "[60]\tvalid_0's l2: 0.229736\n",
      "[61]\tvalid_0's l2: 0.229568\n",
      "[62]\tvalid_0's l2: 0.229263\n",
      "[63]\tvalid_0's l2: 0.229113\n",
      "[64]\tvalid_0's l2: 0.228966\n",
      "[65]\tvalid_0's l2: 0.228767\n",
      "[66]\tvalid_0's l2: 0.228624\n",
      "[67]\tvalid_0's l2: 0.228504\n",
      "[68]\tvalid_0's l2: 0.228363\n",
      "[69]\tvalid_0's l2: 0.22824\n",
      "[70]\tvalid_0's l2: 0.228026\n",
      "[71]\tvalid_0's l2: 0.227834\n",
      "[72]\tvalid_0's l2: 0.227362\n",
      "[73]\tvalid_0's l2: 0.227227\n",
      "[74]\tvalid_0's l2: 0.227025\n",
      "[75]\tvalid_0's l2: 0.226886\n",
      "[76]\tvalid_0's l2: 0.226756\n",
      "[77]\tvalid_0's l2: 0.226485\n",
      "[78]\tvalid_0's l2: 0.226381\n",
      "[79]\tvalid_0's l2: 0.226162\n",
      "[80]\tvalid_0's l2: 0.225954\n",
      "[81]\tvalid_0's l2: 0.225843\n",
      "[82]\tvalid_0's l2: 0.225745\n",
      "[83]\tvalid_0's l2: 0.225672\n",
      "[84]\tvalid_0's l2: 0.225558\n",
      "[85]\tvalid_0's l2: 0.225468\n",
      "[86]\tvalid_0's l2: 0.225221\n",
      "[87]\tvalid_0's l2: 0.225149\n",
      "[88]\tvalid_0's l2: 0.224855\n",
      "[89]\tvalid_0's l2: 0.224659\n",
      "[90]\tvalid_0's l2: 0.224534\n",
      "[91]\tvalid_0's l2: 0.224428\n",
      "[92]\tvalid_0's l2: 0.224302\n",
      "[93]\tvalid_0's l2: 0.224204\n",
      "[94]\tvalid_0's l2: 0.224131\n",
      "[95]\tvalid_0's l2: 0.224071\n",
      "[96]\tvalid_0's l2: 0.224001\n",
      "[97]\tvalid_0's l2: 0.223854\n",
      "[98]\tvalid_0's l2: 0.223646\n",
      "[99]\tvalid_0's l2: 0.223458\n",
      "[100]\tvalid_0's l2: 0.223346\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's l2: 0.223346\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7055997482741816"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_train = lgb.Dataset(train_values, train_labels)\n",
    "lgb_eval = lgb.Dataset(train_values, train_labels, reference=lgb_train)\n",
    "\n",
    "params = {\n",
    "    'objective': 'regression',\n",
    "}\n",
    "\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=100,\n",
    "                valid_sets=lgb_eval,\n",
    "                early_stopping_rounds=10)\n",
    "\n",
    "predicciones_lightgbm = gbm.predict(train_values, num_iteration=gbm.best_iteration)\n",
    "\n",
    "predicciones_lightgbm=[int(x+0.5) for x in predicciones_lightgbm]\n",
    "\n",
    "f1_score(train_labels, predicciones_lightgbm, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones_lightgbm = gbm.predict(test_values, num_iteration=gbm.best_iteration)\n",
    "\n",
    "predicciones_lightgbm =[int(x+0.5) for x in predicciones_lightgbm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_submission = pd.DataFrame(data=predicciones_lightgbm,\n",
    "                             columns=submission_format.columns,\n",
    "                             index=submission_format.index)\n",
    "\n",
    "my_submission.damage_grade = my_submission.damage_grade.round()\n",
    "\n",
    "my_submission.damage_grade = my_submission.damage_grade.astype(int)\n",
    "\n",
    "my_submission.to_csv('submission_lightgbm.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
